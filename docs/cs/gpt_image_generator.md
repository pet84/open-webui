# GPT Image Generator (Pipe) â€“ ÄeskÃ¡ verze

Pipe od **Chris Bloem** pro generovÃ¡nÃ­ a Ãºpravu obrÃ¡zkÅ¯ pÅ™es OpenAI (model **gpt-image-1.5**). V chatu se zobrazuje jako model **â€GPT Image 1â€œ** â€“ vybereÅ¡ ho v vÃ½bÄ›ru modelu, napÃ­Å¡eÅ¡ prompt (nebo pÅ™iloÅ¾Ã­Å¡ obrÃ¡zek a popÃ­Å¡eÅ¡ Ãºpravu), odeÅ¡leÅ¡ a dostaneÅ¡ obrÃ¡zek. NepovÃ­dÃ¡ si, jen generuje/upravuje obrÃ¡zky.

**ZÃ¡vislosti:** `openai`, `pydantic`, `typing`. Bez dalÅ¡Ã­ch knihoven â€“ stahovÃ¡nÃ­ obrÃ¡zkÅ¯ z URL pouÅ¾Ã­vÃ¡ pouze standardnÃ­ `urllib`.

**ObrÃ¡zek z internetu:** MÅ¯Å¾eÅ¡ poslat odkaz na obrÃ¡zek (napÅ™. `https://archenergy.cz/wp-content/uploads/2024/02/rada.jpg`) v textu zprÃ¡vy â€“ pipe obrÃ¡zek stÃ¡hne a pouÅ¾ije pro Ãºpravu. StejnÄ› tak funguje vloÅ¾enÃ½ obrÃ¡zek (data URL) nebo pÅ™iloÅ¾enÃ½ soubor.

**RozliÅ¡enÃ­, rychlost a cena:** NiÅ¾Å¡Ã­ rozliÅ¡enÃ­ = **rychlejÅ¡Ã­** odpovÄ›Ä a **niÅ¾Å¡Ã­ cena**. V pipe mÃ¡Å¡ **dva â€modelyâ€œ**: **GPT Image 1** (1024Ã—1024, zÃ¡kladnÃ­) a **GPT Image 1 HD** (vyÅ¡Å¡Ã­ rozliÅ¡enÃ­). U gpt-image-1.5 je doporuÄenÃ© minimum 1024Ã—1024; 512Ã—512 nenÃ­ podporovanÃ© a pÅ™echod na DALLÂ·E 2 by byl krok zpÄ›t.

## KÃ³d (poÄeÅ¡tÄ›nÃ½ + podpora URL + zÃ¡kladnÃ­/HD)

Pro pouÅ¾itÃ­ v Open WebUI zkopÃ­ruj celÃ½ blok nÃ­Å¾e (od `"""` aÅ¾ po konec tÅ™Ã­dy). PrvnÃ­ Å™Ã¡dek musÃ­ bÃ½t `"""`.

```python
"""
title: GenerÃ¡tor obrÃ¡zkÅ¯ GPT (gpt-image-1.5)
description: RychlÃ½ Pipe pro generovÃ¡nÃ­ a Ãºpravu obrÃ¡zkÅ¯ pomocÃ­ gpt-image-1.5 (vÄetnÄ› obrÃ¡zkÅ¯ z URL)
author: Chris Bloem (ÄeskÃ¡ verze)
version: 1.6.0
license: MIT
requirements: typing, pydantic, openai
environment_variables:
disclaimer: PouÅ¾itÃ­ na vlastnÃ­ odpovÄ›dnost. 1.6.0 PÅ™epnuto na model gpt-image-1.5.
"""

import json
import random
import base64
import asyncio
import re
import tempfile
import os
import logging
import urllib.request
from typing import List, AsyncGenerator, Callable, Awaitable

from pydantic import BaseModel, Field
from openai import OpenAI

# Regex pro detekci obrÃ¡zkÅ¯ z URL v textu (napÅ™. https://example.com/obrazek.jpg)
URL_IMAGE_PATTERN = re.compile(
    r"https?://[^\s<>\"']+\.(?:jpe?g|png|gif|webp)",
    re.IGNORECASE,
)


class Pipe:
    """Pipe: v chatu dva modely â€“ GPT Image 1 (zÃ¡kladnÃ­) a GPT Image 1 HD."""

    class Valves(BaseModel):
        OPENAI_API_KEYS: str = Field(
            default="", description="OpenAI API klÃ­Äe, oddÄ›lenÃ© ÄÃ¡rkou"
        )
        IMAGE_NUM: int = Field(default=1, description="PoÄet obrÃ¡zkÅ¯ (1â€“10)")
        IMAGE_SIZE: str = Field(
            default="1024x1024",
            description="Velikost pro GPT Image 1 (zÃ¡kladnÃ­): 1024x1024, 1536x1024, 1024x1536, auto",
        )
        IMAGE_SIZE_HD: str = Field(
            default="1536x1024",
            description="Velikost pro GPT Image 1 HD (vyÅ¡Å¡Ã­ rozliÅ¡enÃ­, pomalejÅ¡Ã­ a draÅ¾Å¡Ã­)",
        )
        IMAGE_QUALITY: str = Field(
            default="auto",
            description="Kvalita: high, medium, low, auto",
        )
        MODERATION: str = Field(
            default="auto",
            description="Moderace: auto (vÃ½chozÃ­) nebo low",
        )
        BASE_URL: str = Field(
            default=None,
            description=(
                "VolitelnÄ›: Base URL endpointu (napÅ™. https://api.openai.com/v1 nebo proxy). "
                "PrÃ¡zdnÃ© = vÃ½chozÃ­."
            ),
        )

    def __init__(self):
        self.type = "manifold"
        self.id = "gpt_image_1"
        self.name = "ChatGPT: "
        self.valves = self.Valves()
        self.emitter: Callable[[dict], Awaitable[None]] | None = None

    def _get_base_url(self) -> str | None:
        val = getattr(self.valves, "BASE_URL", None)
        if val is not None and len(val.strip()) > 0:
            return val.strip()
        return None

    async def emit_status(self, message: str = "", done: bool = False):
        if self.emitter:
            await self.emitter(
                {"type": "status", "data": {"description": message, "done": done}}
            )

    def pipes(self) -> List[dict]:
        # Dva modely: zÃ¡kladnÃ­ a HD (1024 minimum u gpt-image-1.5)
        return [
            {"id": "gpt-image-1", "name": "GPT Image 1"},
            {"id": "gpt-image-1-hd", "name": "GPT Image 1 HD"},
        ]

    def convert_message_to_prompt(self, messages: List[dict]) -> tuple[str, List[dict]]:
        """
        Z poslednÃ­ uÅ¾ivatelskÃ© zprÃ¡vy vytÃ¡hne text (prompt) a seznam obrÃ¡zkÅ¯.
        ObrÃ¡zky mohou bÃ½t: data URL (base64), nebo odkaz na internet (https://...).
        PoloÅ¾ky s URL majÃ­ tvar {"url": "https://..."} a pÅ™ed volÃ¡nÃ­m API se stÃ¡hnou.
        """
        for msg in reversed(messages):
            if msg.get("role") != "user":
                continue

            content = msg.get("content")

            if isinstance(content, list):
                text_parts: List[str] = []
                image_data_list: List[dict] = []

                for part in content:
                    if part.get("type") == "text":
                        text_parts.append(part.get("text", ""))
                    elif part.get("type") == "image_url":
                        url = part.get("image_url", {}).get("url", "")
                        if url.startswith("data:"):
                            # VloÅ¾enÃ½ obrÃ¡zek (base64)
                            header, data = url.split(";base64,", 1)
                            mime = header.split("data:")[-1]
                            image_data_list.append({"mimeType": mime, "data": data})
                        elif url.startswith("http://") or url.startswith("https://"):
                            # Odkaz na obrÃ¡zek z internetu â€“ pÅ™edÃ¡me URL, stÃ¡hneme v pipe()
                            image_data_list.append({"url": url})

                prompt = (
                    " ".join(text_parts).strip() or "Uprav pÅ™iloÅ¾enÃ½ obrÃ¡zek podle popisu."
                )
                return prompt, image_data_list

            if isinstance(content, str):
                # ObrÃ¡zky v Markdownu jako data:...;base64,...
                pattern = r"!\[[^\]]*\]\(data:([^;]+);base64,([^)]+)\)"
                matches = re.findall(pattern, content)
                image_data_list = [{"mimeType": m, "data": d} for m, d in matches]
                clean = re.sub(pattern, "", content).strip()

                # V textu hledÃ¡me i URL obrÃ¡zkÅ¯ (napÅ™. https://archenergy.cz/.../rada.jpg)
                for match in URL_IMAGE_PATTERN.finditer(clean):
                    image_data_list.append({"url": match.group(0)})
                # Z promptu odstranÃ­me nalezenÃ© URL, aby zÅ¯stal jen popis Ãºpravy
                clean = URL_IMAGE_PATTERN.sub("", clean).strip()

                prompt = clean or "Uprav pÅ™iloÅ¾enÃ½ obrÃ¡zek podle popisu."
                return prompt, image_data_list

        return "Uprav pÅ™iloÅ¾enÃ½ obrÃ¡zek podle popisu.", []

    def _get_system_content(self, messages: List[dict]) -> str:
        """VrÃ¡tÃ­ text systÃ©movÃ© zprÃ¡vy (odkaz, instrukce). Pokud je vÃ­c systÃ©movÃ½ch, spojÃ­ je."""
        parts = []
        for msg in messages:
            if msg.get("role") != "system":
                continue
            content = msg.get("content")
            if isinstance(content, str) and content.strip():
                parts.append(content.strip())
            elif isinstance(content, list):
                for part in content:
                    if part.get("type") == "text" and (part.get("text") or "").strip():
                        parts.append(part.get("text", "").strip())
        return "\n\n".join(parts) if parts else ""

    async def _fetch_url_to_base64(self, url: str) -> dict:
        """StÃ¡hne obrÃ¡zek z URL a vrÃ¡tÃ­ dict s mimeType a base64 data."""
        def _get() -> dict:
            req = urllib.request.Request(url, headers={"User-Agent": "OpenWebUI-Pipe/1.0"})
            with urllib.request.urlopen(req, timeout=15) as r:
                data = r.read()
                if len(data) > 25 * 1024 * 1024:
                    raise ValueError("ObrÃ¡zek z URL pÅ™esahuje limit 25 MB")
                ct = r.headers.get("Content-Type", "image/jpeg")
                mime = ct.split(";")[0].strip().lower()
                if mime not in ("image/png", "image/jpeg", "image/jpg", "image/webp"):
                    mime = "image/jpeg"
                return {"mimeType": mime, "data": base64.b64encode(data).decode()}
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, _get)

    async def _resolve_images(self, imgs: List[dict]) -> List[dict]:
        """PoloÅ¾ky s klÃ­Äem 'url' stÃ¡hne a pÅ™evede na mimeType + data."""
        resolved: List[dict] = []
        for img in imgs:
            if "url" in img:
                try:
                    resolved.append(await self._fetch_url_to_base64(img["url"]))
                except Exception as e:
                    raise ValueError(f"Nelze stÃ¡hnout obrÃ¡zek z {img['url']}: {e}")
            else:
                resolved.append(img)
        return resolved

    async def _run_blocking(self, fn: Callable, *args, **kwargs):
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, lambda: fn(*args, **kwargs))

    def _pick_api_key(self) -> str | None:
        keys = [k.strip() for k in self.valves.OPENAI_API_KEYS.split(",") if k.strip()]
        if not keys:
            return None
        return random.choice(keys)

    async def generate_image(
        self,
        prompt: str,
        model: str,
        n: int,
        size: str,
        quality: str,
    ) -> AsyncGenerator[str, None]:
        """VolÃ¡ OpenAI images/generations â€“ novÃ½ obrÃ¡zek z textu."""
        await self.emit_status("ğŸ–¼ï¸ Generuji...")
        key = self._pick_api_key()
        if not key:
            yield "Chyba: OPENAI_API_KEYS nenÃ­ nastaveno"
            await self.emit_status("âŒ GenerovÃ¡nÃ­ obrÃ¡zku selhalo", done=True)
            return

        client = OpenAI(api_key=key, base_url=self._get_base_url())

        size_arg = None if not size or size.lower() == "auto" else size
        quality_arg = None if not quality or quality.lower() == "auto" else quality

        def _call_gen():
            kwargs = {
                "model": model,
                "prompt": prompt,
                "n": n,
                "moderation": self.valves.MODERATION,
            }
            if size_arg:
                kwargs["size"] = size_arg
            if quality_arg:
                kwargs["quality"] = quality_arg
            return client.images.generate(**kwargs)

        try:
            resp = await self._run_blocking(_call_gen)
            for i, img in enumerate(resp.data, 1):
                yield f"![image_{i}](data:image/png;base64,{img.b64_json})"
            await self.emit_status("ğŸ‰ GenerovÃ¡nÃ­ obrÃ¡zku dokonÄeno", done=True)
        except Exception as e:
            yield f"Chyba pÅ™i generovÃ¡nÃ­: {e}"
            await self.emit_status("âŒ GenerovÃ¡nÃ­ obrÃ¡zku selhalo", done=True)

    async def edit_image(
        self,
        base64_images: List[dict],
        prompt: str,
        model: str,
        n: int,
        size: str,
        quality: str,
    ) -> AsyncGenerator[str, None]:
        """VolÃ¡ OpenAI images/edits â€“ Ãºprava pÅ™iloÅ¾enÃ½ch obrÃ¡zkÅ¯ podle promptu."""
        await self.emit_status("âœ‚ï¸ Upravuji obrÃ¡zek...")
        key = self._pick_api_key()
        if not key:
            yield "Chyba: OPENAI_API_KEYS nenÃ­ nastaveno"
            await self.emit_status("âŒ Ãšprava obrÃ¡zku selhala", done=True)
            return

        client = OpenAI(api_key=key, base_url=self._get_base_url())

        images_array = []
        for i, img_dict in enumerate(base64_images, start=1):
            try:
                data = base64.b64decode(img_dict["data"])
                if len(data) > 25 * 1024 * 1024:
                    raise ValueError("ObrÃ¡zek pÅ™esahuje limit 25 MB")

                suffix = {
                    "image/png": ".png",
                    "image/jpeg": ".jpg",
                    "image/jpg": ".jpg",
                    "image/webp": ".webp",
                }.get(img_dict["mimeType"])
                if not suffix:
                    raise ValueError(f"NepodporovanÃ½ formÃ¡t: {img_dict['mimeType']}")

                image = (f"file{i}{suffix}", data, img_dict["mimeType"])
                images_array.append(image)
            except Exception as e:
                raise ValueError(f"Chyba dekÃ³dovÃ¡nÃ­ obrÃ¡zku: {e}")

        size_arg = None if not size or size.lower() == "auto" else size
        quality_arg = None if not quality or quality.lower() == "auto" else quality

        def _call_edit(images):
            kwargs = {
                "model": model,
                "image": images,
                "prompt": prompt,
                "n": n,
            }
            if size_arg:
                kwargs["size"] = size_arg

            extra_body = {}
            if quality_arg:
                extra_body["quality"] = quality_arg
            if extra_body:
                kwargs["extra_body"] = extra_body

            return client.images.edit(**kwargs)

        try:
            resp = await self._run_blocking(_call_edit, images_array)
            for i, img in enumerate(resp.data, 1):
                yield f"![image_{i}](data:image/png;base64,{img.b64_json})"
            await self.emit_status("ğŸ‰ Ãšprava obrÃ¡zku dokonÄena", done=True)
        except Exception as e:
            yield f"Chyba pÅ™i ÃºpravÄ› obrÃ¡zku: {e}"
            await self.emit_status("âŒ Ãšprava obrÃ¡zku selhala", done=True)

    async def pipe(
        self,
        body: dict,
        __event_emitter__: Callable[[dict], Awaitable[None]] = None,
    ) -> AsyncGenerator[str, None]:
        """HlavnÃ­ vstup: zprÃ¡vy z chatu. Pokud jsou obrÃ¡zky (vloÅ¾enÃ© nebo z URL) â†’ edit, jinak â†’ generovÃ¡nÃ­."""
        self.emitter = __event_emitter__
        msgs = body.get("messages", [])

        # KterÃ½ â€modelâ€œ uÅ¾ivatel vybral â€“ podle toho zvolÃ­me rozliÅ¡enÃ­ (zÃ¡kladnÃ­ vs HD)
        selected = (body.get("model") or "").strip() or "gpt-image-1"
        if selected == "gpt-image-1-hd":
            size = self.valves.IMAGE_SIZE_HD
        else:
            size = self.valves.IMAGE_SIZE

        model_id = "gpt-image-1.5"
        n = min(max(1, self.valves.IMAGE_NUM), 10)
        quality = self.valves.IMAGE_QUALITY

        prompt, imgs = self.convert_message_to_prompt(msgs)

        # SystÃ©movÃ½ prompt: pokud v chatu je systÃ©movÃ¡ zprÃ¡va (odkaz, instrukce), slouÄÃ­me ji s promptem
        # Pak staÄÃ­ v chatu pÅ™idat obrÃ¡zek a napsat â€pracujâ€œ â€“ Ãºprava probÄ›hne podle systÃ©mu
        system_content = self._get_system_content(msgs)
        if system_content:
            prompt = (system_content.strip() + "\n\n" + (prompt or "").strip()).strip() or system_content.strip()

        # ObrÃ¡zky z URL stÃ¡hneme a pÅ™evedeme na base64
        if imgs:
            imgs = await self._resolve_images(imgs)

        if imgs:
            async for out in self.edit_image(
                base64_images=imgs,
                prompt=prompt,
                model=model_id,
                n=n,
                size=size,
                quality=quality,
            ):
                yield out
        else:
            async for out in self.generate_image(
                prompt=prompt,
                model=model_id,
                n=n,
                size=size,
                quality=quality,
            ):
                yield out
```

## NastavenÃ­ (Valves)

- **OPENAI_API_KEYS** â€“ jeden nebo vÃ­ce OpenAI API klÃ­ÄÅ¯ (oddÄ›lenÃ© ÄÃ¡rkou).
- **IMAGE_NUM** â€“ poÄet obrÃ¡zkÅ¯ v jednom bÄ›hu (1â€“10); pro jednu koÄiÄku nech 1.
- **IMAGE_SIZE** â€“ rozliÅ¡enÃ­ pro **GPT Image 1** (zÃ¡kladnÃ­): `1024x1024`, `1536x1024`, `1024x1536`, `auto`.
- **IMAGE_SIZE_HD** â€“ rozliÅ¡enÃ­ pro **GPT Image 1 HD**: vÃ½chozÃ­ `1536x1024`. MÅ¯Å¾eÅ¡ zmÄ›nit na `1024x1536` (na vÃ½Å¡ku) atd.
- **IMAGE_QUALITY** â€“ `high`, `medium`, `low`, `auto`.
- **MODERATION** â€“ `auto` nebo `low`.
- **BASE_URL** â€“ volitelnÄ›, napÅ™. `https://api.openai.com/v1` nebo adresa proxy.

## PouÅ¾itÃ­

1. V Open WebUI vyber v chatu jako â€modelâ€œ:
   - **GPT Image 1** â€“ zÃ¡kladnÃ­ 1024Ã—1024 (rychlejÅ¡Ã­, levnÄ›jÅ¡Ã­),
   - **GPT Image 1 HD** â€“ vyÅ¡Å¡Ã­ rozliÅ¡enÃ­ (**IMAGE_SIZE_HD**).
2. Pro **generovÃ¡nÃ­**: napiÅ¡ text (napÅ™. â€obrÃ¡zek koÄiÄkyâ€œ) a odeÅ¡li.
3. Pro **Ãºpravu**:
   - **PÅ™iloÅ¾enÃ½ soubor** â€“ pÅ™iloÅ¾ obrÃ¡zek k zprÃ¡vÄ› a napiÅ¡, co s nÃ­m udÄ›lat.
   - **ObrÃ¡zek z internetu** â€“ napiÅ¡ do zprÃ¡vy odkaz na obrÃ¡zek a popis Ãºpravy (pipe URL rozpoznÃ¡ a stÃ¡hne).
   - **SystÃ©movÃ½ prompt + â€pracujâ€œ:** V nastavenÃ­ chatu (nebo v prvnÃ­ systÃ©movÃ© zprÃ¡vÄ›) nastav **odkaz / instrukci** â€“ co se mÃ¡ s obrÃ¡zkem dÄ›lat. V chatu pak jen pÅ™iloÅ¾ obrÃ¡zek a napiÅ¡ **pracuj**. Pipe slouÄÃ­ systÃ©movÃ½ text s tvou zprÃ¡vou a poÅ¡le to do API â€“ Ãºprava probÄ›hne podle systÃ©mu.

OpakovanÃ© hlÃ¡Å¡ky â€Generujiâ€¦â€œ / â€GenerovÃ¡nÃ­ obrÃ¡zku dokonÄenoâ€œ v jednom bÄ›hu bÃ½vajÃ­ tÃ­m, Å¾e Open WebUI pipe spustÃ­ vÃ­cekrÃ¡t; samotnÃ½ kÃ³d s `IMAGE_NUM=1` vracÃ­ jeden obrÃ¡zek na jedno volÃ¡nÃ­.

### KolikrÃ¡t se pipe opravdu volÃ¡? (log na serveru)

Aby sis ovÄ›Å™il, Å¾e za to mÅ¯Å¾e vÃ­c poÅ¾adavkÅ¯ z UI, mÅ¯Å¾eÅ¡ na **zaÄÃ¡tek** metody `pipe()` (hned za `self.emitter = __event_emitter__`) doÄasnÄ› pÅ™idat:

```python
import logging
logging.getLogger("open_webui.functions").warning("GPT Image pipe() volÃ¡nÃ­")
```

Pak **restartuj backend** Open WebUI, poÅ¡li jednu zprÃ¡vu (jeden obrÃ¡zek) a v **logu serveru** (kde bÄ›Å¾Ã­ Open WebUI â€“ konzole, stdout, nebo soubor z dockeru/PM2) hledej Å™Ã¡dek `GPT Image pipe() volÃ¡nÃ­`. KolikrÃ¡t se objevÃ­ za jednu tvoji zprÃ¡vu, tolikrÃ¡t se pipe opravdu spustil. Pokud je to vÃ­c neÅ¾ 1Ã—, volÃ¡nÃ­ posÃ­lÃ¡ frontend nebo middleware (ne nÃ¡Å¡ kÃ³d). Log pak mÅ¯Å¾eÅ¡ zase odstranit.
